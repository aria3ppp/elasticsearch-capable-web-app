input {
    jdbc {
        jdbc_connection_string => "jdbc:postgresql://${POSTGRES_HOST}:5432/${POSTGRES_DB}"
        jdbc_user => "${POSTGRES_USER}"
        jdbc_password => "${POSTGRES_PASSWORD}"
        jdbc_driver_library => "/opt/logstash/vendor/jdbc/postgresql-42.4.2.jar"
        jdbc_driver_class => "org.postgresql.Driver"
        statement_filepath => "/usr/share/logstash/config/queries/sync-posts.sql"
        use_column_value => true
        tracking_column => "contributed_at"
        tracking_column_type => "timestamp"
        schedule => "*/5 * * * * *"
    }
}

filter {
    # set index action based on 'id_deleted' field
    if [deleted] {
        mutate { add_field => { "[@metadata][action]" => "delete" } }
    } else {
        mutate { add_field => { "[@metadata][action]" => "index" } }
    }
    # @metadata attributes are temporal to logstash pipelines and won't present to elasticsearch at output
        
    # remove 'deleted' field plus unneeded fields including ones that were added by logstash
    mutate {
        remove_field => ["contributed_at", "deleted", "@version", "@timestamp"]
    }
}

output {
    stdout { codec => rubydebug { metadata => true } }

    elasticsearch {
        hosts => ["http://elasticsearch:9200"] # URL of the ES docker container - docker would resolve it for us.
        action => "%{[@metadata][action]}"
        index => "posts"
        document_id => "%{id}"
    }
}
